# by_diff_filename_v2.3
import os
import json
import hashlib
import time
import bridge
from major_version_identifier import MajorVersionIdentifier


class VersionIdentifierPost():
    def __init__(self, path1, path2, filecount):
        # path1 = 待测文件路径, path2 = 数据库路径("Source Code File Diff With Hash CLUSTER"), hashfile = 存储待测文件哈希值的json文件
        self.check_path = path1
        self.source_path = path2
        self.dataJSON = {}
        self.filecount = filecount
        self.file_count_per_version = {}
        self.major_version = ""
        self.final_version = ""
        #待测文件字典
        self.filedict = {}

    def print_header(self):
        print("")
        print("##############################################################################################################################################################")
        print("COMMENCING ADVANCED VERSION CHECK...")
        print("HASHING THE CONTENTS OF THE PROVIDED SOURCE FILE!")
        print("##############################################################################################################################################################")

    def hashing(self):
        for subdir, dirs, files in os.walk(self.check_path):
                for file in files:
                    path = os.path.join(subdir, file)
                    processed_path = path[7:]
                    with open(path, "rb") as f:
                        data = f.read()
                        md5hash = hashlib.md5(data).hexdigest()
                    self.filedict[processed_path] = md5hash
        self.hash_dump()

    def hash_dump(self):
        out_file = open("./temp/hashcheck.json", "w")
        json.dump(self.filedict, out_file, indent=6)
        out_file.close()
        with open("./temp/hashcheck.json", "r") as f:
            self.hashdata = json.load(f)
        print("Hashing Done!")
        #print("Hashcheck file is located at: ", os.getcwd() +'\\'+ "hashcheck.json")

    # Function that sort path(key) and its hash value(value) to a dictionary
    def readPathandHashValue(self, d, current_path=''):
        result = {}
        for key, value in d.items():
            if current_path:
                key_path = current_path + "\\" + key
            else:
                key_path = key

            if isinstance(value, dict):
                nested_paths = self.readPathandHashValue(value, key_path)
                result.update(nested_paths)
            else:
                result[key_path] = value

        return result

    # 寻找对应大版本的JSON文件
    def findJSON(self):
        for root, dirs, files in os.walk(self.source_path):
            for file in files:
                if file.split("_")[0] == self.major_version:
                    with open(os.path.join(self.source_path, file), "r") as f:
                        data = json.load(f)

        return data

    # 断代小版本
    def identifyVersion(self):
        self.print_header()
        self.hashing()
        self.start_time = time.time()
        # 断代大版本
        test = MajorVersionIdentifier(self.check_path, "./dataset/json/Diff_File.json")
        self.major_version = test.identifyMajorVersion()
        # 寻找大版本对应的JSON文件
        self.dataJSON = self.findJSON()

        # 开始断代小版本
        # 判断是否存在小版本
        if len(self.dataJSON) <= 1:
            self.final_version = self.major_version + ".0"
        else:
            # 开始计算共有多少文件的哈希值是相同的
            for JSONfilename, files in self.dataJSON.items():
                version1, version2 = str.split(JSONfilename, "__")
                dic = self.readPathandHashValue(files)

                same_file_count = 0
                key_count = 0
                filter_file = [".c", ".cc", ".h", ".py", ".bzl"]
                for key, value in dic.items():
                    # 过滤文件
                    if os.path.splitext(key)[-1] in filter_file:
                        key_count += 1
                        # 判断哈希值是否一样
                        try:
                            if self.hashdata[key] == value:
                                same_file_count += 1
                        except KeyError:
                            continue
                    # 计算比例
                    try:
                        self.file_count_per_version[version2] = same_file_count / key_count
                    except ZeroDivisionError:
                        self.file_count_per_version[version2] = 0

                    # 得出最终结果
                    count_max = 0
                    for key, value in self.file_count_per_version.items():
                        if value >= count_max:
                            self.final_version = key
                            count_max = value

        self.end_time = time.time()
        self.printResult()
        self.createJSON()
        self.executeTime()
        print("")

    def printResult(self):
        print("Your version is most compatible with: Tensorflow", self.final_version)

    def createJSON(self):
        with open("./temp/result.json", "w") as f:
            json.dump(self.file_count_per_version, f, indent=4)

    def executeTime(self):
        print("Execution Time: ", self.end_time - self.start_time, "s")

    def returnResult(self):
        return self.final_version

